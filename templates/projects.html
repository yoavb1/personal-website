{% extends 'base.html' %}

{% block title %}Projects{% endblock %}

{% block content %}
<h2 style="text-align: center; margin-bottom: 50px; font-size: 2.2em;">Projects</h2>

<div style="max-width: 850px; margin: 0 auto; display: flex; flex-direction: column; gap: 80px;">

  <!-- Project 4 -->
  <section style="padding: 30px; border: 1px solid #ddd; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.05);">
    <h3 style="margin-bottom: 20px;"><i class="fas fa-comments" style="color: #f39c12; margin-right: 10px;"></i>Words Matter: Exploring Text Presentation in AI-Driven Conversations</h3>
    <p style="line-height: 1.7;">
      This ongoing project explores human-AI chatbot interaction, focusing on how different text and history display formats influence users’ communication experience, trust, cognitive workload, and task performance. By manipulating key elements of conversational display, such as word-by-word versus all-at-once message delivery, and visible versus on-demand conversation history, we aim to better understand how interface design choices shape user behavior and perceptions in chatbot interactions.
    </p>
  </section>

  <!-- Project 1 -->
  <section style="padding: 30px; border: 1px solid #ddd; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.05);">
    <h3 style="margin-bottom: 20px;"><i class="fas fa-brain" style="color: #4a90e2; margin-right: 10px;"></i>When to Rely on AI: Modeling Human Use of Decision Support Systems</h3>
    <p style="line-height: 1.7;">In this project, we examined how people decide whether to use a decision support system (DSS) when making uncertain, high-stakes decisions, such as determining whether a patient requires medical intervention.</p>
    <p style="line-height: 1.7;">We developed a normative model that defines the optimal conditions for purchasing such a system, and ran an online experiment simulating a physician’s task. Participants reviewed patient data and made binary decisions (intervention or not). Before each decision, they could choose whether to pay for support from a system that provided its own recommendation.</p>
    <p style="line-height: 1.7;">We found that using the DSS improved both decision accuracy and speed, but participants didn’t always use it optimally. Their decisions to purchase support were shaped mainly by prior experiences.</p>
    <p style="line-height: 1.7;"><strong>Key insight:</strong> People's use of decision support system is guided not only by rational cost-benefit calculations, but also by how the system performed in the past. This has important implications for designing systems that people learn to trust and adopt over time.</p>
  </section>

  <!-- Project 2 -->
  <section style="padding: 30px; border: 1px solid #ddd; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.05);">
    <h3 style="margin-bottom: 20px;"><i class="fas fa-retweet" style="color: #7b68ee; margin-right: 10px;"></i>When Help Repeats What You Already Know: How Redundancy Affects Trust and Use of Decision Support</h3>
    <p style="line-height: 1.7;">This project explores how people interact with decision support systems (DSS) that provide information similar to, or different from, what they already know. Across three experiments, we studied when users choose to pay for DSS help, how redundant information affects their performance, and how it shapes their trust in the system.</p>
    <p style="line-height: 1.7;">We found that people were more likely to seek help from systems that offered new, non-redundant insights. Receiving information that simply confirmed what they already believed sometimes led to lower performance, and trust in the system varied depending on how useful its input was.</p>
    <p style="line-height: 1.7;">These findings suggest that when designing decision aids, it's not enough for a system to be accurate, it also needs to add value beyond what the user already knows. Helping users recognize that value is key to building trust and ensuring effective use.</p>
    <p style="line-height: 1.7;"><strong>Key insight:</strong> People are more likely to use decision support when it offers new information rather than simply confirming what they already believe. Redundant support can reduce performance and trust. For decision aids to be effective, they must not only be accurate but also provide unique information.</p>

  </section>

  <!-- Project 3 -->
  <section style="padding: 30px; border: 1px solid #ddd; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.05);">
    <h3 style="margin-bottom: 20px;"><i class="fas fa-layer-group" style="color: #20c997; margin-right: 10px;"></i>Beyond Accuracy: How Interface Design Shapes the Use of Decision Support Systems</h3>
    <p style="line-height: 1.7;">This project investigates how uncertainty and the way a decision support system (DSS) presents information affect people’s tendency to use it, and how that, in turn, shapes their performance, workload, and perceptions.</p>
    <p style="line-height: 1.7;">We found that people were more likely to purchase aid from DSS when their own information was highly uncertain or the DSS was highly accurate. They also used the system more effectively when its output was integrated into the same display as the raw information, even if more detailed formats technically gave them more data.</p>
    <p style="line-height: 1.7;"><strong>Key takeaway:</strong> When people can choose whether to engage with a DSS, the format of its output matters, as its accuracy does. Intuitive, well-integrated displays encourage use and lead to better decisions.</p>
  </section>

<section style="padding: 30px; border: 1px solid #ddd; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.05); margin-bottom: 80px;">
  <h3 style="margin-bottom: 20px;">
    <i class="fas fa-shield-alt" style="color: #e74c3c; margin-right: 10px;"></i>
    Investing in Cybersecurity: Human Decision-Making in Protective Systems
  </h3>
  <p style="line-height: 1.7;">
    This project explored how people decide to invest in cybersecurity tools like firewalls, alert systems, and cyber insurance.
  </p>
  <p style="line-height: 1.7;">
      We developed a simulated cybersecurity operations environment, where participants classified events as safe or malicious and could choose to invest in different protections to reduce risk or damage.
  </p>
  <p style="line-height: 1.7;">
    While participants often preferred alert systems, their choices didn’t always match what would actually benefit them most. In many cases, they overinvested in less effective tools and underinvested in the ones that could help more.
  </p>
  <p style="line-height: 1.7; margin-top: 20px;">
    <strong>Key insight:</strong> Users often rely on intuition rather than strategy when investing in cybersecurity. Strategic policies can support more informed and effective decisions about cybersecurity tools investments.



  </p>
</section>


</div>
{% endblock %}
